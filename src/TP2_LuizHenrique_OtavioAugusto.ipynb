{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Prático 2\n",
    "## Realidade Aumentada\n",
    "#### Introdução à Computação Visual - 2020/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Integrantes:\n",
    "* Otávio Augusto Silva - 2016006808\n",
    "* Luiz Henrique de Melo Santos - 2017014464"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Considerações iniciais:\n",
    "\n",
    "* Este código foi elaborado primariamente por meio de adaptação do código-fonte fornecido durante a apresentação do professor Erickson R. Nascimento durante a Escola de Verão de Ciência da Computação de 2017, da DCC-UFMG. O vídeo da apresentação pode ser acessado por meio deste [LINK](https://youtu.be/1z0Sga8_RxE).\n",
    "* Este código foi executado em um ambiente Conda com Python 3.5, em sistema operacional Windows - devido às bibliotecas FreeGlut e Pygame, que apresentaram vários problemas com novas versões do Python, bem como em sistemas como MacOS e Ubuntu.\n",
    "* O código-fonte _'objloader.py'_ fornecido juntamente com a especificação do trabalho teve de ser alterado em alguns trechos para correção de alguns bugs, que estavam impossibilitando a correta execução da aplicação. Os trechos modificados foram marcados com a tag _'# MODIFICADO'_.\n",
    "* Não conseguimos de maneira alguma obter o video no formato AVI com todos os quadros de detecção e localização do objeto, bem como o cubo inserido na posicao do objeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calibração da câmera\n",
    "\n",
    "A calibração da câmera foi feita por meio de 7 imagens '.jpg' obtidas a partir do vídeo de entrada original.</br>As imagens utilizadas e os resultados obtidos encontram-se no diretório _'./camera_calibration/'_, nesta mesma pasta.</br>Os parâmetros obtidos na etapa de calibração da câmera foram os seguintes (retirados da saída retornada pelo Octave):\n",
    "\n",
    "%-- Focal length:\n",
    "fc = [ 610.879708372179834 ; 567.989563803793203 ];\n",
    "\n",
    "%-- Principal point:\n",
    "cc = [ 147.535469452871865 ; 378.898762622333265 ];\n",
    "\n",
    "%-- Skew coefficient:\n",
    "alpha_c = 0.000000000000000;\n",
    "\n",
    "%-- Distortion coefficients:\n",
    "kc = [ 0.221906437598475 ; -0.144942670158401 ; 0.071131863616536 ; -0.034706440480340 ; 0.000000000000000 ];\n",
    "\n",
    "%-- Focal length uncertainty:\n",
    "fc_error = [ 75.155595825974373 ; 60.441536246691285 ];\n",
    "\n",
    "%-- Principal point uncertainty:\n",
    "cc_error = [ 25.814231043535663 ; 35.864563206899405 ];\n",
    "\n",
    "%-- Skew coefficient uncertainty:\n",
    "alpha_c_error = 0.000000000000000;\n",
    "\n",
    "%-- Distortion coefficients uncertainty:\n",
    "kc_error = [ 0.171427317703732 ; 0.152596209865342 ; 0.032279667448496 ; 0.017045499576809 ; 0.000000000000000 ];\n",
    "\n",
    "%-- Image size:\n",
    "nx = 578;\n",
    "ny = 434;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports para a aplicação (caso não tenha, favor fazer a instalação das seguintes bibliotecas para a correta execução):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pygame\n",
    "# !pip install PyOpenGL\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from OpenGL.GL import *\n",
    "from objloader import *\n",
    "from objloader import *\n",
    "from OpenGL.GLU import *\n",
    "from OpenGL.GLUT import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definição dos arquivos que serão utilizados pela aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagem do alvo para ser identificado no vídeo de entrada\n",
    "TARGET = './alvo.jpg'\n",
    "\n",
    "# Objeto 3D a ser renderizado no vídeo de entrada\n",
    "OBJECT = \"Pikachu.obj\"\n",
    "\n",
    "# Vídeo de entrada a ser analisado, e que receberá a renderização do objeto 3D\n",
    "VIDEO_INPUT = './tp2-icv-input.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Etapas de \"baixo nível\": detecção de bordas / detecção do alvo no vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_coefficient(X, Y):\n",
    "    '''\n",
    "    Determina o Coeficiente de Correlacao de Pearson, de acordo com a formula (https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
    "    \n",
    "    INPUTS:\n",
    "    patch1 - matriz de representacao da imagem do alvo\n",
    "    patch2 - matriz de representacao da imagem extraida do video de entrada\n",
    "    \n",
    "    OUTPUTS:\n",
    "    0 - imagens nao possuem semelhanca\n",
    "    product - produto obtidos por meio do calculo da Correlacao\n",
    "    '''\n",
    "    \n",
    "    product = np.mean((X - X.mean()) * (Y - Y.mean()))\n",
    "    stds = X.std() * Y.std()\n",
    "    return 0 if stds == 0 else product/stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findTargets(img):\n",
    "    '''\n",
    "    Encontra os possiveis alvos na imagem do frame atual recebido como entrada\n",
    "    \n",
    "    INPUT:\n",
    "    img - imagem do frame atual extraido do video de entrada\n",
    "    \n",
    "    OUTPUT:\n",
    "    markers - coordenadas dos alvos localizados no frame atual analisado no video\n",
    "    '''\n",
    "    \n",
    "    t_size = 100\n",
    "    global target\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, img_gray = cv2.threshold(img_gray, 128, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    markers = []\n",
    "    edged = cv2.Canny(img_gray, 100, 200)\n",
    "    cnt, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    \n",
    "    for c in cnt:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 12, True)\n",
    "\n",
    "        if len(approx) == 4:\n",
    "            c_indices = None\n",
    "            c_cords = None\n",
    "            \n",
    "            dst = np.array([[0, 0], [0, t_size], [t_size, t_size], [t_size, 0]], dtype=\"float32\")\n",
    "            indices = np.arange(4)\n",
    "            \n",
    "            for rotations in range(4):\n",
    "                src = np.array(approx.reshape(4,2), dtype=\"float32\")\n",
    "                matrix = cv2.getPerspectiveTransform(src, dst[indices])\n",
    "                warped = cv2.warpPerspective(img_gray, matrix, (t_size, t_size))\n",
    "                ret, binaryImg = cv2.threshold(warped, 127, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "                \n",
    "                # Calculo do Coeficiente de Correlacao de Pearson\n",
    "                dist = correlation_coefficient(binaryImg, target)\n",
    "                if dist > 0.6:\n",
    "                    min_dist = dist\n",
    "                    c_indices = indices\n",
    "                    c_cords = src\n",
    "                    break\n",
    "                    \n",
    "                target = cv2.rotate(target, cv2.ROTATE_90_CLOCKWISE)\n",
    "            if c_cords is not None:\n",
    "                markers.append((c_cords, c_indices))\n",
    "    return markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Etapas visuais: início da framework / execução do vídeo / renderização do objeto 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initOpenGL(img):\n",
    "    '''\n",
    "    Inicia as instâncias do OpenGL, bem como define os parametros a serem utilizados por ele\n",
    "    \n",
    "    INPUT\n",
    "    img - frame atual analisado, do video\n",
    "    '''\n",
    "    \n",
    "    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "    glLoadIdentity()\n",
    "    \n",
    "    background = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    background = cv2.flip(background, 0)\n",
    "    height, width, channels = background.shape\n",
    "    background = np.frombuffer(background.tostring(), dtype=background.dtype, count=height * width * channels)\n",
    "    background.shape = (height, width, channels)\n",
    "    \n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "    glBindTexture(GL_TEXTURE_2D, pikachu_tex)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)\n",
    "    glTexImage2D(GL_TEXTURE_2D, 0, 3, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, background)\n",
    "    glDepthMask(GL_FALSE)\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    \n",
    "    glPushMatrix()\n",
    "    glLoadIdentity()\n",
    "    gluOrtho2D(0, width, 0, height)\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glBindTexture(GL_TEXTURE_2D, pikachu_tex)\n",
    "    glTexImage2D(GL_TEXTURE_2D, 0, 3, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, background)\n",
    "    glPushMatrix()\n",
    "    \n",
    "    glBegin(GL_QUADS)\n",
    "    glTexCoord2i(0, 0); glVertex2i(0, 0)\n",
    "    glTexCoord2i(1, 0); glVertex2i(width, 0)\n",
    "    glTexCoord2i(1, 1); glVertex2i(width, height)\n",
    "    glTexCoord2i(0, 1); glVertex2i(0, height)\n",
    "    glEnd()\n",
    "    \n",
    "    glPopMatrix()\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glPopMatrix()\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glDepthMask(GL_TRUE)\n",
    "    glDisable(GL_TEXTURE_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Etapas escalonadoras: callback para execucao continua do programa em cada um dos frame do video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applicationInit(width=640, height=480): \n",
    "    '''\n",
    "    Promove a configuracao dos parametros que serao utilizados pela aplicacao,\n",
    "    tal como os parametros da matriz e o tamanho das imagens que serao analizadas\n",
    "    durante a execucao\n",
    "    \n",
    "    INPUT:\n",
    "    width - largura da imagem\n",
    "    height - altura da imagem\n",
    "    '''\n",
    "    \n",
    "    glutInit()\n",
    "    glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE)\n",
    "    glutInitWindowSize(width, height)\n",
    "    glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_CONTINUE_EXECUTION)\n",
    "    window = glutCreateWindow(b'Trabalho Pratico 02 - Realidade Aumentada')\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "\n",
    "    global video, cameraMatrix, distCoeffs, obj, pikachu_tex, target\n",
    "    \n",
    "    '''\n",
    "    ** ATENCAO **\n",
    "    Os valores da calibracao foram alterados de ultima hora para correcao,\n",
    "    pois os exibidos anteriormente estavam desregulando consideravelemnte\n",
    "    a posicao de renderizacao do objeto 3D - os novos valores foram obtidos\n",
    "    apos uma nova calibracao, e os resultados melhorados consideravelmente\n",
    "    '''\n",
    "    fx, fy = 1175.32408, 1180.34557\n",
    "    cx, cy = 933.43195, 544.17464\n",
    "    cameraMatrix = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])  # Matriz de parametros intrinsecos\n",
    "    distCoeffs = np.array([0.07378, -0.04224, -0.00111, -0.00524, 0.00000])  # Coeficientes de distorcao\n",
    "    \n",
    "    fovy = 60\n",
    "    aspect = width/height\n",
    "    gluPerspective(fovy, aspect, 0.01, 100.0)\n",
    "    \n",
    "    target = cv2.imread(TARGET)\n",
    "    target = cv2.resize(target, (100, 100), interpolation = cv2.INTER_AREA)\n",
    "    target = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "    _, target = cv2.threshold(target, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    \n",
    "    obj = OBJ(OBJECT, swapyz=True)\n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "    pikachu_tex = glGenTextures(1)\n",
    "    video = cv2.VideoCapture(VIDEO_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glutCallback():\n",
    "    '''\n",
    "    Permite que todos os frame do video sejam analizados\n",
    "    e que os objetos possam ser renderizados em cada um deles\n",
    "    '''\n",
    "    \n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    \n",
    "    _, img = video.read()\n",
    "    initOpenGL(img)\n",
    "    targets = findTargets(img)\n",
    "    \n",
    "    for rect, index in targets:\n",
    "        imagePoints = np.array(rect, dtype=\"float32\")\n",
    "        objectPoints = np.array([[-1, -1, 1], [ 1, -1, 1], [ 1,  1, 1], [-1,  1, 1]], dtype=\"float32\")\n",
    "        _, rvecs, tvecs = cv2.solvePnP(objectPoints[index], imagePoints, cameraMatrix, distCoeffs)\n",
    "        rot_mat, _ = cv2.Rodrigues(rvecs)\n",
    "        mat = np.transpose(np.array([\n",
    "            [ rot_mat[0][0],  rot_mat[0][1],  rot_mat[0][2],  tvecs[0]], \n",
    "            [-rot_mat[1][0], -rot_mat[1][1], -rot_mat[1][2], -tvecs[1]], \n",
    "            [-rot_mat[2][0], -rot_mat[2][1], -rot_mat[2][2], -tvecs[2]], \n",
    "            [           0.0,            0.0,            0.0,       1.0]]))\n",
    "        \n",
    "        glBindTexture(GL_TEXTURE_2D, pikachu_tex)\n",
    "        glEnable(GL_TEXTURE_2D)\n",
    "        glLoadMatrixd(mat)\n",
    "        glCallList(obj.gl_list)\n",
    "        \n",
    "    glutSwapBuffers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    Funcao principal para inicio da aplicacao de Realidade Aumentada\n",
    "    '''\n",
    "    \n",
    "    applicationInit()\n",
    "    glutDisplayFunc(glutCallback)\n",
    "    glutIdleFunc(glutPostRedisplay)\n",
    "    glutMainLoop()\n",
    "    \n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
